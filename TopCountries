# Import necessary libraries including SparkSession and desc

import pyspark 
from pyspark.sql import SparkSession
from pyspark.sql.functions import desc

# Create a Spark session
spark = SparkSession.builder.appName("TopCountries").getOrCreate()

# Load the data and read the csv file using the spark.read.csv method
data = spark.read.csv("customers.csv", header=True, inferSchema=True)

# Group data by country and count the number of customers in each country
country_customers = data.groupBy("Country").count()

# Sort the countries in descending order by the count to get top countries
# Select top 10 countries with the most customers using limit(10)
top_countries = country_customers.orderBy(desc("count")).limit(10)

# Print out using show()
top_countries.show()

# Stop the Spark session
spark.stop()

# Write the output to a file
top_countries.write.csv("top_countries.csv", header=True)


# Write the output to a file
top_countries.write.csv("top_countries.csv", header=True)

