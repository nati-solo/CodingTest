from pyspark.sql import SparkSession
from pyspark.sql.functions import desc

# Create a Spark session
spark = SparkSession.builder.appName("TopCountries").getOrCreate()

# Load the data into a DataFrame and read the CSV file into a DataFrame using the spark.read.csv method
data = spark.read.csv("customers.csv", header=True, inferSchema=True)

# Group data by country and count the number of customers in each country
country_customers = data.groupBy("Country").count()

# Sort the countries in descending order by the count to get top countries
top_countries = country_customers.orderBy(desc("count")).limit(10)

# Select top 10 countries with the most customers using limit(10)
# Print out using show()
top_countries.show()

# Stop the Spark session
spark.stop()
