# Import required libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import avg, sum, col
from pyspark.sql.functions import desc

# Start Spark session
spark = SparkSession.builder.appName("AvgPriceVolume").getOrCreate()

# Read input data from csv files
products_df = spark.read.csv("products.csv", header=True)
orders_df = spark.read.csv("orders.csv", header=True)

# Join the two datasets on StockCode
df = products_df.join(orders_df, "StockCode")

# Group by StockCode and calculate average UnitPrice using statistics module and total Quantity
stats_df = df.groupBy("StockCode").agg(
    avg("UnitPrice").alias("avg_price"),
    sum("Quantity").alias("total_qty"))

# Filter for top 25 by total_qty
top25_df = stats_df.orderBy(desc("total_qty")).limit(25)

# Write output to AvgPriceVolume.csv file
stats_df.write.csv("AvgPriceVolume.csv", header=True)

# Display computed statistics 
stats_df.show()

# Calculate correlation between the average unit price and sales volume across all products
# Correlation = +1 a perfect positive correlation. Aa avg unit price increases, the sales volume increases. 
# Correlation = -1 a perfect negative correlation. As avg unit price increases, the sales volume decreases.
# Correlation ~0 - no correlation
corr = stats_df.select(col("avg_price"), col("total_qty")).corr("avg_price", "total_qty")
print("Correlation between average unit price and sales volume: ", corr)

"""
# Optional way to show the relationships is using an overlay bar-line graph
# Import libraries
import matplotlib.pyplot as plt

# Generate bar plot using filtered DataFrame
bar_df = top25_df.select("StockCode", "total_qty")
bar = bar_df.plot(kind="bar", x="StockCode", y="total_qty", rot=0)

# Generate line plot using filtered DataFrame
line_df = top25_df.orderBy("StockCode").select("StockCode", "avg_price")
line = line_df.plot(kind="line", x="StockCode", y="avg_price", rot=0, ax=bar)

# Overlay and display plots
plt.legend(["Quantity Ordered", "Price"])
plt.xlabel("Product Code")
plt.show()
"""
